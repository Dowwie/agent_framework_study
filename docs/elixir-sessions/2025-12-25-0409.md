# Elixir Design Session - 2025-12-25

## Session Context
- **Continuation of**: `docs/elixir-sessions/2025-12-24-0639.md`
- **Trigger**: Gap analysis (`fathom_gap.md`) identified missing Deep Agent pillars
- **Session goal**: Add dimensions 14-17 to address gaps in sub-agent architecture, artifact memory, system prompts, and context handoff

## Prior Session Summary

Dimensions 1-13 completed on Dec 24, 2025:
1. Core Architecture: Deep Agents via GenServer + Task
2. Process Structure: SessionController GenServer, Task.async for steps
3. State Model: PostgreSQL + Redis with Ecto embedded schemas
4. Message Protocol: Lightweight reference structs, 4 ETS tables, ex_hash_ring
5. Tool System: Ecto schemas, introspection, @tool_description
6. LLM Integration: Req + Behaviour adapters, PubSub streaming, Hammer, :fuse
7. Memory/Context: Token budget + eviction, pgvector + pg_bm25
8. Multi-Agent: SessionController orchestrates, no peer-to-peer
9. Observability: Telemetry + OpenTelemetry, step-level granularity
10. Error Handling: Feed errors to LLM, checkpoint recovery, max iterations
11. Interrupts/Breakpoints: Hybrid (step-level + runtime), timeout with default
12. Human-in-the-Loop: Step type + tool, PubSub → Phoenix Channel → WebSocket
13. Time Travel: Hybrid snapshots + events, L1 view-only inspection

Architectural revisions: Broadway → GenServer + Task; Explicit Graph → Pattern Matching

---

## Gap Analysis Summary

From `fathom_gap.md`:

| Deep Agent Pillar | Current Coverage | Action Needed |
|-------------------|------------------|---------------|
| Explicit Planning | Strong | None |
| Hierarchical Delegation | Weak | Dimension 14 |
| Persistent Memory | Partial | Dimension 15 |
| Extreme Context Engineering | Implicit | Dimension 16-17 |

---

## Dimension 14: Sub-Agent Architecture

**Problem Statement:**
The current design has SessionController running all steps itself. True Deep Agents require:
- Orchestrator that delegates to specialized sub-agents
- Sub-agents with isolated context windows
- Clean result synthesis (sub-agents return summaries, not full context)

**Options to Discuss:**

### Option A: Inline Agent Types (Current + Enhancement)
Keep single SessionController but add agent "profiles" that configure behavior:
```elixir
%Step{
  type: :research,
  agent_profile: :researcher,  # Determines tools + system prompt
  ...
}
```
- Pros: Simpler, no process hierarchy change
- Cons: No true context isolation, all work in one LLM conversation

### Option B: Sub-Agent Processes
SessionController spawns sub-agent GenServers per step:
```
SessionController (orchestrator)
  └── spawns SubAgent for step N
        └── SubAgent has own context, returns synthesized result
```
- Pros: True context isolation, parallel sub-agents possible
- Cons: More complexity, process overhead

### Option C: Task-Based Sub-Agents
Sub-agents are just Tasks with isolated context:
```elixir
Task.async(fn ->
  AgentFramework.SubAgent.run(:researcher, step, isolated_context)
end)
```
- Pros: Lighter than GenServers, natural fit with current Task.async pattern
- Cons: No persistent sub-agent state across steps

**Discussion:**
Key insight: True context isolation requires sub-agents to have their own LLM conversation threads.
However, GenServer overhead is unnecessary if we externalize context to ETS.

Questions explored:
1. **Multi-turn sub-agents?** Yes - sub-agents need to run multiple LLM calls internally before returning
2. **Inter-agent communication?** Hub-and-spoke via orchestrator (not peer-to-peer)
3. **Sub-agent lifecycle?** Ephemeral Tasks, but context persists in ETS

This gives GenServer benefits (persistence, resumability) without GenServer complexity.

**Decision:**
**Choice**: Option C extended: Task-Based Sub-Agents with ETS-Backed Context

**Architecture:**
```
SessionController (orchestrator)
    │
    ├── spawns Task (sub_agent_id: "researcher_1")
    │       └── loads context from ETS[:sub_agent_contexts]
    │       └── runs multi-turn loop internally
    │       └── saves context to ETS[:sub_agent_contexts]
    │       └── returns synthesized result
    │
    └── can spawn another Task for same sub_agent_id later
            └── context restored from ETS (resumable)
```

**Rationale:**
- Tasks are lightweight and fit existing pattern
- ETS provides context persistence without process overhead
- Hub-and-spoke keeps coordination simple and debuggable
- Multi-turn execution happens within Task, isolated from orchestrator

**New ETS table:**
| Table | Purpose |
|-------|---------|
| `:sub_agent_contexts` | Sub-agent conversation histories, keyed by {session_id, sub_agent_id} |

**New schema:**
```elixir
defmodule AgentFramework.Schemas.SubAgentContext do
  embedded_schema do
    field :session_id, :binary_id
    field :sub_agent_id, :string  # e.g., "researcher_1"
    field :agent_type, Ecto.Enum, values: [:researcher, :coder, :writer, :reviewer, :custom]
    field :messages, {:array, :map}  # conversation history
    field :tool_results, {:array, :map}
    field :artifacts_created, {:array, :string}  # paths
    field :created_at, :utc_datetime_usec
    field :updated_at, :utc_datetime_usec
  end
end
```

**Trade-offs accepted:**
- Sub-agents can't talk directly to each other (must go through orchestrator)
- Context must be serializable to ETS (no in-memory closures)

---

## Dimension 15: Artifact/Workspace Memory

**Problem Statement:**
Deep Agents write intermediate results to files and reference paths, not contents:
- Research notes → `workspace/research/quantum_computing.md`
- Code drafts → `workspace/code/module.ex`
- Context builder injects paths, not full file contents

Current design uses database-centric storage (ETS, PostgreSQL) without filesystem artifacts.

**Options to Discuss:**

### Option A: Pure Database (Current)
Keep everything in ETS/Postgres. "Artifacts" are JSONB fields.
- Pros: Simpler, no file I/O, easier to cluster
- Cons: Not true Deep Agent pattern, context bloat

### Option B: Hybrid Database + Filesystem
Add workspace directories per session:
```
workspaces/
  └── {session_id}/
      ├── research/
      ├── code/
      └── artifacts/
```
Database stores metadata + paths. Context builder references paths.
- Pros: True Deep Agent pattern, natural file artifacts
- Cons: File I/O overhead, harder to cluster

### Option C: Object Storage (S3-compatible)
Artifacts go to S3/MinIO with presigned URLs:
```elixir
artifact = %Artifact{
  session_id: "...",
  type: :research,
  path: "s3://bucket/session_id/research/notes.md"
}
```
- Pros: Scales to clusters, persistent
- Cons: Network latency, more infrastructure

**Discussion:**
Key considerations:
1. **Deployment model**: Multi-node from start requires shared storage
2. **Storage options evaluated**: NFS (ops complexity), Postgres BLOBs (not designed for files), S3 (cloud-native)
3. **Context loading**: Reference + tool approach keeps context lean

**Decision:**
**Choice**: S3-Compatible Storage with Behaviour Abstraction

**Architecture:**
```elixir
defmodule AgentFramework.Storage do
  @callback write(session_id, path, content) :: {:ok, artifact_url} | {:error, term()}
  @callback read(artifact_url) :: {:ok, content} | {:error, term()}
  @callback list(session_id, prefix) :: {:ok, [artifact_url]} | {:error, term()}
  @callback delete(artifact_url) :: :ok | {:error, term()}
end

# Implementations:
# - AgentFramework.Storage.S3 (production, uses ex_aws_s3)
# - AgentFramework.Storage.Local (dev/testing)
```

**Path conventions:**
```
s3://{bucket}/{session_id}/{artifact_type}/{filename}

Types: research/, code/, drafts/, data/, logs/
```

**Artifact schema:**
```elixir
defmodule AgentFramework.Schemas.Artifact do
  embedded_schema do
    field :session_id, :binary_id
    field :sub_agent_id, :string
    field :type, Ecto.Enum, values: [:research, :code, :draft, :data, :log]
    field :path, :string  # s3://bucket/path
    field :filename, :string
    field :content_type, :string
    field :size_bytes, :integer
    field :created_by_step, :integer
    field :created_at, :utc_datetime_usec
  end
end
```

**Context integration:**
- Context shows artifact paths exist
- Agent must call `read_artifact` tool to get content
- Keeps context predictably lean

**Built-in tools:**
```elixir
# Added to default tool set
AgentFramework.Tools.WriteArtifact  # Write to workspace
AgentFramework.Tools.ReadArtifact   # Read from workspace
AgentFramework.Tools.ListArtifacts  # List session artifacts
```

**Rationale:**
- S3-compatible scales to multi-node clusters
- Behaviour abstraction allows local dev with MinIO or filesystem
- Reference + tool approach follows Deep Agent pattern ("know where to find")
- Artifact metadata in ETS/Postgres for fast listing

**Trade-offs accepted:**
- Network latency for artifact reads (acceptable for LLM-scale operations)
- Additional infrastructure (MinIO for dev, S3 for prod)

---

## Dimension 16: System Prompts Framework

**Problem Statement:**
The design has infrastructure but no actual prompts. Deep Agents need:
- 1000+ token system prompts per agent type
- Procedural instructions ("when to pause", "when to spawn sub-agent")
- Tool usage examples
- File naming conventions

**Options to Discuss:**

### Option A: Embedded Strings
Prompts are module attributes or string literals:
```elixir
defmodule AgentFramework.Prompts.Researcher do
  @system_prompt """
  You are a research agent...
  """
end
```
- Pros: Simple, compile-time
- Cons: Hard to iterate, no templating

### Option B: Template Files
Prompts live in `priv/prompts/*.md` with EEx templating:
```
priv/prompts/
  ├── orchestrator.md.eex
  ├── researcher.md.eex
  ├── coder.md.eex
  └── writer.md.eex
```
- Pros: Easy to edit, version control, dynamic values
- Cons: File I/O at startup

### Option C: Database-Stored Prompts
Prompts in Postgres, versioned, updateable at runtime:
```elixir
AgentFramework.Prompts.get(:researcher, version: :latest)
```
- Pros: A/B testing, runtime updates
- Cons: Overkill for initial implementation

**Discussion:**
Key considerations:
1. Deep Agents need substantial prompts (1000-3000 tokens)
2. Prompts should be easy to iterate without code changes
3. Framework should ship with battle-tested defaults
4. Users need simple override mechanism

**Decision:**
**Choice**: Template Files with Directory Override

**Directory layout:**
```
priv/prompts/
├── _shared/                    # Reusable partials
│   ├── artifact_conventions.md.eex
│   ├── tool_guidelines.md.eex
│   └── hitl_protocols.md.eex
├── orchestrator.md.eex         # Main session orchestrator
├── researcher.md.eex           # Research sub-agent
├── coder.md.eex               # Coding sub-agent
├── writer.md.eex              # Writing sub-agent
└── reviewer.md.eex            # Review sub-agent
```

**Prompt structure:**
```markdown
# [Agent Type] Agent

## Identity
You are a <%= @agent_type %> agent working on: <%= @goal %>

## Capabilities
- Tools available: <%= @tool_names |> Enum.join(", ") %>
- Workspace: <%= @workspace_path %>

## Procedural Instructions
### When to Plan
### When to Use Tools
<%= render "_shared/tool_guidelines.md.eex", assigns %>
### Artifact Conventions
<%= render "_shared/artifact_conventions.md.eex", assigns %>
### Human Interaction
<%= render "_shared/hitl_protocols.md.eex", assigns %>

## Output Format
...
```

**Loading and override:**
```elixir
defmodule AgentFramework.Prompts do
  @default_dir :code.priv_dir(:agent_framework) |> Path.join("prompts")

  def get(agent_type, assigns \\ %{}) do
    path = resolve_path(agent_type)
    EEx.eval_file(path, assigns: Map.to_list(assigns))
  end

  defp resolve_path(agent_type) do
    custom_dir = Application.get_env(:agent_framework, :prompts_dir)
    filename = "#{agent_type}.md.eex"

    cond do
      custom_dir && File.exists?(Path.join(custom_dir, filename)) ->
        Path.join(custom_dir, filename)
      true ->
        Path.join(@default_dir, filename)
    end
  end
end
```

**Override mechanism:**
```elixir
# config/config.exs
config :agent_framework, :prompts_dir, "priv/my_prompts"
# Missing files fall back to framework defaults
```

**Rationale:**
- EEx templates allow dynamic values (goal, tools, workspace)
- Shared partials reduce duplication
- Directory override is simple and predictable
- Framework ships with working defaults

**Trade-offs accepted:**
- File I/O on prompt load (cached after first load)
- EEx adds parsing overhead (negligible vs LLM latency)

---

## Dimension 17: Context Handoff Protocol

**Problem Statement:**
When sub-agents return results to the orchestrator, how is context compressed?
- Raw dump = context explosion
- Summarization = information loss
- Structured extraction = balanced

**Options to Discuss:**

### Option A: Free-Form Summary
Sub-agent generates natural language summary:
```
"I researched quantum computing and found 5 key papers. Main findings: ..."
```
- Pros: Flexible, LLM-native
- Cons: Inconsistent structure, potential omissions

### Option B: Structured Result Schema
Define schema for each agent type's output:
```elixir
defmodule AgentFramework.Results.ResearchResult do
  embedded_schema do
    field :summary, :string
    field :sources, {:array, :string}
    embeds_many :key_findings, KeyFinding
    field :artifact_paths, {:array, :string}
  end
end
```
- Pros: Consistent, parseable, predictable token usage
- Cons: Less flexible, may miss nuance

### Option C: Hybrid with Extraction
LLM generates free-form + structured extraction:
```elixir
%{
  narrative: "I researched quantum computing and...",
  structured: %ResearchResult{...},
  artifacts: ["workspace/research/notes.md"]
}
```
- Pros: Best of both worlds
- Cons: More tokens, more complexity

**Discussion:**
Key considerations:
1. Orchestrator needs: what was done, what was produced, what's next
2. Full sub-agent context is too large to pass back
3. Need predictable structure for programmatic handling
4. Need LLM interpretation for reasoning/recommendations

**Decision:**
**Choice**: Hybrid Extraction - Code facts + LLM interpretation

**Base result schema (all sub-agents):**
```elixir
defmodule AgentFramework.Schemas.SubAgentResult do
  embedded_schema do
    field :sub_agent_id, :string
    field :agent_type, Ecto.Enum, values: [:researcher, :coder, :writer, :reviewer, :custom]
    field :status, Ecto.Enum, values: [:completed, :partial, :blocked, :failed]

    # Code-extracted (deterministic)
    field :artifacts_created, {:array, :string}
    field :artifacts_modified, {:array, :string}
    field :tools_used, {:array, :string}
    field :token_usage, :map  # %{input: N, output: M}
    field :duration_ms, :integer

    # LLM-extracted (interpretation)
    field :summary, :string  # 1-2 sentences
    field :recommendations, {:array, :string}
    field :blockers, {:array, :string}
    field :confidence, :float

    # Type-specific (LLM-extracted)
    embeds_one :type_specific, :map
  end
end
```

**Extraction flow:**
```elixir
def synthesize_result(sub_agent_context) do
  # Step 1: Code extracts deterministic facts
  facts = %{
    artifacts_created: extract_artifact_paths(sub_agent_context),
    tools_used: extract_tool_names(sub_agent_context),
    token_usage: sum_token_usage(sub_agent_context),
    duration_ms: calculate_duration(sub_agent_context)
  }

  # Step 2: LLM extracts interpretation
  interpretation_prompt = """
  Based on your work, provide:
  1. Summary (1-2 sentences)
  2. Status: completed | partial | blocked | failed
  3. Recommendations for next steps
  4. Any blockers encountered
  5. Confidence level (0-1)
  6. [Type-specific fields]
  """

  llm_result = LLM.chat([...context..., interpretation_prompt])
  interpretation = parse_interpretation(llm_result)

  # Step 3: Merge
  Map.merge(facts, interpretation)
end
```

**Type-specific extensions:**
```elixir
# :researcher
%{sources: [...], key_findings: [...], knowledge_gaps: [...]}

# :coder
%{files_created: [...], tests_status: :passing | :failing, impl_notes: "..."}

# :writer
%{document_type: :report, word_count: N, sections: [...]}
```

**Rationale:**
- Code extraction is deterministic and fast (artifacts, tokens, timing)
- LLM extraction captures reasoning (summary, recommendations, confidence)
- Hybrid gets best of both worlds without doubling output
- Structured schema enables programmatic handling by orchestrator

**Trade-offs accepted:**
- Extra LLM call for interpretation (acceptable, it's the sub-agent's final call)
- Schema must handle partial/malformed LLM responses

---

## Session Progress

| Dimension | Status | Decision |
|-----------|--------|----------|
| 14: Sub-Agent Architecture | Complete | Task-based with ETS context |
| 15: Artifact/Workspace Memory | Complete | S3-compatible with behaviour |
| 16: System Prompts Framework | Complete | EEx templates with directory override |
| 17: Context Handoff Protocol | Complete | Hybrid extraction (code + LLM) |

---

## Session Summary

**Date**: 2025-12-25
**Duration**: Extended session
**Trigger**: Gap analysis identified missing Deep Agent pillars

### Decisions Made

| # | Dimension | Decision |
|---|-----------|----------|
| 14 | Sub-Agent Architecture | Task-based sub-agents with ETS-backed context. Hub-and-spoke via orchestrator. |
| 15 | Artifact/Workspace Memory | S3-compatible storage (behaviour abstraction). Reference + tool pattern. |
| 16 | System Prompts Framework | EEx templates in priv/prompts/. Directory override. Ship with defaults. |
| 17 | Context Handoff Protocol | Hybrid extraction: code extracts facts, LLM extracts interpretation. |

### New Components

**ETS Tables (added):**
- `:sub_agent_contexts` - Sub-agent conversation histories

**Schemas (added):**
- `SubAgentContext` - Persistent context for sub-agents
- `Artifact` - Metadata for workspace artifacts
- `SubAgentResult` - Structured result from sub-agents

**Behaviours (added):**
- `AgentFramework.Storage` - Pluggable artifact storage

**Modules (added):**
```
lib/agent_framework/
├── sub_agent/
│   ├── runner.ex           # Task-based execution
│   └── context.ex          # ETS context management
├── storage/
│   ├── behaviour.ex        # Storage behaviour
│   ├── s3.ex              # S3 implementation
│   └── local.ex           # Dev/test implementation
├── prompts/
│   └── loader.ex          # EEx template loading
└── tools/builtin/
    ├── write_artifact.ex
    ├── read_artifact.ex
    └── list_artifacts.ex
```

**Files (added):**
```
priv/prompts/
├── _shared/
│   ├── artifact_conventions.md.eex
│   ├── tool_guidelines.md.eex
│   └── hitl_protocols.md.eex
├── orchestrator.md.eex
├── researcher.md.eex
├── coder.md.eex
├── writer.md.eex
└── reviewer.md.eex
```

### Updated Decision Summary (All 17 Dimensions)

| # | Dimension | Decision |
|---|-----------|----------|
| 1 | Core Architecture | Deep Agents via GenServer + Task |
| 2 | Process Structure | SessionController GenServer, Task.async for steps |
| 3 | State Model | PostgreSQL + Redis with Ecto embedded schemas |
| 4 | Message Protocol | Lightweight reference structs, 4 ETS tables, ex_hash_ring |
| 5 | Tool System | Ecto schemas, introspection, @tool_description |
| 6 | LLM Integration | Req + Behaviour adapters, PubSub streaming, Hammer, :fuse |
| 7 | Memory/Context | Token budget + eviction, pgvector + pg_bm25 |
| 8 | Multi-Agent | SessionController orchestrates, no peer-to-peer |
| 9 | Observability | Telemetry + OpenTelemetry, step-level granularity |
| 10 | Error Handling | Feed errors to LLM, checkpoint recovery, max iterations |
| 11 | Interrupts/Breakpoints | Hybrid (step-level + runtime), timeout with default |
| 12 | Human-in-the-Loop | Step type + tool, PubSub → Phoenix Channel → WebSocket |
| 13 | Time Travel | Hybrid snapshots + events, L1 view-only inspection |
| 14 | Sub-Agent Architecture | Task-based with ETS context, hub-and-spoke |
| 15 | Artifact/Workspace Memory | S3-compatible storage, reference + tool |
| 16 | System Prompts | EEx templates, directory override, ship defaults |
| 17 | Context Handoff | Hybrid extraction (code facts + LLM interpretation) |

### Gap Analysis Resolution

| Deep Agent Pillar | Before | After |
|-------------------|--------|-------|
| Explicit Planning | Strong | Strong (unchanged) |
| Hierarchical Delegation | Weak | **Strong** (Dim 14, 17) |
| Persistent Memory | Partial | **Strong** (Dim 15) |
| Extreme Context Engineering | Implicit | **Strong** (Dim 16) |

### Next Steps

1. Update `docs/elixir-design.md` with new dimensions
2. Revise module structure diagram
3. Update implementation order
4. Close gap analysis document

---

*Session completed: 2025-12-25 ~04:30 AM*
